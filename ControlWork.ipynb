{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Work for Lessons\n",
    "\n",
    "This control work is designed to test your knowledge gained from the two lessons. The tasks will cover a range of topics, including data exploration, preprocessing, feature engineering, and model evaluation. We will use the Breast Cancer Wisconsin Diagnostic dataset for this control work.\n",
    "\n",
    "### Task 1: Load and Explore the Data\n",
    "\n",
    "1. Import the required libraries: pandas, numpy, seaborn, and matplotlib.pyplot.\n",
    "2. Load the Breast Cancer Wisconsin Diagnostic dataset using the ['load_breast_cancer'](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html) function from sklearn. Choose such return_X_y and as_frame parameters values that the function returns two objects: a pandas DataFrame and a pandas Series.\n",
    "3. Concatenate the DataFrame and the Series into a single DataFrame using the ['concat'](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) function from pandas. Display the first 5 rows.\n",
    "4. Generate descriptive statistics of the dataset using the `.describe()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint for Task 1\n",
    "# 1. Import the required libraries: pandas as pd, numpy as np, seaborn as sns, matplotlib.pyplot as plt\n",
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Concatenate the features and target into a single dataframe and display the first 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Generate descriptive statistics(.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Data Preprocessing\n",
    "1. Check for missing data in the dataset. If there are missing values, handle them appropriately.\n",
    "2. Scale the dataset that contains X using the 'StandardScaler' from sklearn.\n",
    "3. Split the dataset into training and testing sets using a 80/20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint for Task 2\n",
    "# 1. Check for missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Scale the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Split the dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Data Visualization\n",
    "1. Visualize the distribution of features using seaborn's pairplot function.\n",
    "2. Create a correlation heatmap using seaborn to visualize the correlations between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint for Task 3\n",
    "# 1. Visualize the distribution of features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Create a correlation heatmap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Model Training and Evaluation\n",
    "1. Import the RandomForestClassifier and LogisticRegression models from sklearn.\n",
    "2. Train the RandomForestClassifier and LogisticRegression models on the training set.\n",
    "3. Evaluate the performance of both models on the test set using accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint for Task 4\n",
    "# 1. Import the models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Evaluate the performance\n",
    "from sklearn.metrics import accuracy_score"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
